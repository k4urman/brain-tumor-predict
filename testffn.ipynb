{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65d3d3d-772f-4cad-abbe-9a785e74dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Downloads/NIH Glioblastoma data.csv...\n",
      "Data loaded successfully! Shape: (21634, 164)\n",
      "\n",
      "Sample columns: ['primary_site', 'disease_type', 'updated_datetime', 'case_id', 'submitter_id', 'index_date', 'state', 'consent_type', 'project.project_id', 'demographic.ethnicity', 'demographic.gender', 'demographic.race', 'demographic.vital_status', 'demographic.age_at_index', 'demographic.submitter_id', 'demographic.days_to_birth', 'demographic.demographic_id', 'demographic.age_is_obfuscated', 'demographic.updated_datetime', 'demographic.days_to_death']\n",
      "\n",
      "First few rows preview:\n",
      "  primary_site disease_type                  updated_datetime  \\\n",
      "0        Brain      Gliomas  2025-01-05T15:37:46.919964-06:00   \n",
      "1        Brain      Gliomas  2025-01-05T15:37:46.919964-06:00   \n",
      "2        Brain      Gliomas  2025-01-05T15:37:46.919964-06:00   \n",
      "\n",
      "                                case_id  submitter_id index_date     state  \\\n",
      "0  0078b0c4-68a9-483b-9aab-61156d263213  TCGA-14-1034  Diagnosis  released   \n",
      "1  0078b0c4-68a9-483b-9aab-61156d263213  TCGA-14-1034  Diagnosis  released   \n",
      "2  0078b0c4-68a9-483b-9aab-61156d263213  TCGA-14-1034  Diagnosis  released   \n",
      "\n",
      "       consent_type project.project_id demographic.ethnicity  \n",
      "0  Consent by Death           TCGA-GBM          not reported  \n",
      "1  Consent by Death           TCGA-GBM          not reported  \n",
      "2  Consent by Death           TCGA-GBM          not reported  \n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Creating severity_level from existing features...\n",
      "Severity level created. Range: 25.0 - 75.0\n",
      "Mean severity: 50.8\n",
      "\n",
      "Numerical features: ['age_at_diagnosis', 'alcohol_intensity', 'tobacco_frequency', 'tobacco_onset', 'days_to_death', 'karnofsky_score']\n",
      "Categorical features: ['gender', 'race', 'ethnicity', 'vital_status', 'tumor_grade', 'morphology', 'site_of_biopsy', 'laterality', 'prior_malignancy', 'prior_treatment', 'another_malignancy', 'alcohol_history', 'metastasis', 'disease_status', 'progression', 'who_grade']\n",
      "Warning: Column 'alcohol_intensity' has all missing values, filled with 0\n",
      "Warning: Column 'alcohol_intensity' has zero variance, skipping normalization\n",
      "\n",
      "Final processed shape: (21634, 22)\n",
      "Target range: 0.25 - 0.75\n",
      "\n",
      "Processed data shape: (21634, 22)\n",
      "Number of features: 22\n",
      "Number of samples: 21634\n",
      "Training Medical Cancer Severity Prediction Model...\n",
      "Epoch [10/100], Loss: 0.0009\n",
      "Epoch [20/100], Loss: 0.0005\n",
      "Epoch [30/100], Loss: 0.0004\n",
      "Epoch [40/100], Loss: 0.0003\n",
      "Epoch [50/100], Loss: 0.0003\n",
      "Epoch [60/100], Loss: 0.0003\n",
      "Epoch [70/100], Loss: 0.0003\n",
      "Epoch [80/100], Loss: 0.0003\n",
      "Epoch [90/100], Loss: 0.0003\n",
      "Epoch [100/100], Loss: 0.0003\n",
      "\n",
      "Evaluation Results:\n",
      "Mean Absolute Error: 0.76\n",
      "Root Mean Squared Error: 1.54\n",
      "\n",
      "Model saved as 'medical_cancer_severity_model.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Custom Dataset for Medical Data\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Data Preprocessing Function\n",
    "def preprocess_medical_data(df, create_severity=True):\n",
    "    \"\"\"\n",
    "    Preprocesses NIH Glioblastoma medical data with categorical encoding and normalization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create severity level if it doesn't exist\n",
    "    if create_severity and 'severity_level' not in df.columns:\n",
    "        print(\"\\nCreating severity_level from existing features...\")\n",
    "        severity = np.zeros(len(df))\n",
    "        \n",
    "        # Base severity on multiple factors (0-100 scale)\n",
    "        # Factor 1: Tumor grade (0-30 points)\n",
    "        if 'diagnoses.tumor_grade' in df.columns:\n",
    "            grade_map = {'G1': 5, 'G2': 15, 'G3': 25, 'G4': 30, 'GX': 15}\n",
    "            severity += df['diagnoses.tumor_grade'].map(grade_map).fillna(15)\n",
    "        \n",
    "        # Factor 2: Vital status (0-25 points)\n",
    "        if 'demographic.vital_status' in df.columns:\n",
    "            vital_map = {'Alive': 0, 'Dead': 25}\n",
    "            severity += df['demographic.vital_status'].map(vital_map).fillna(12)\n",
    "        \n",
    "        # Factor 3: Metastasis (0-20 points)\n",
    "        if 'diagnoses.metastasis_at_diagnosis' in df.columns:\n",
    "            meta_map = {'Yes': 20, 'No': 0, 'yes': 20, 'no': 0}\n",
    "            severity += df['diagnoses.metastasis_at_diagnosis'].map(meta_map).fillna(5)\n",
    "        \n",
    "        # Factor 4: Prior malignancy (0-15 points)\n",
    "        if 'diagnoses.prior_malignancy' in df.columns:\n",
    "            prior_map = {'Yes': 15, 'No': 0, 'yes': 15, 'no': 0}\n",
    "            severity += df['diagnoses.prior_malignancy'].map(prior_map).fillna(5)\n",
    "        \n",
    "        # Factor 5: Disease status (0-10 points)\n",
    "        if 'diagnoses.last_known_disease_status' in df.columns:\n",
    "            status_map = {'Tumor free': 0, 'With tumor': 10, 'not reported': 5}\n",
    "            severity += df['diagnoses.last_known_disease_status'].map(status_map).fillna(5)\n",
    "        \n",
    "        # Clip to 0-100 range\n",
    "        df['severity_level'] = np.clip(severity, 0, 100)\n",
    "        print(f\"Severity level created. Range: {df['severity_level'].min():.1f} - {df['severity_level'].max():.1f}\")\n",
    "        print(f\"Mean severity: {df['severity_level'].mean():.1f}\")\n",
    "    \n",
    "    # Select relevant features from the NIH dataset\n",
    "    feature_mapping = {\n",
    "        'demographic.gender': 'gender',\n",
    "        'demographic.race': 'race',\n",
    "        'demographic.ethnicity': 'ethnicity',\n",
    "        'diagnoses.age_at_diagnosis': 'age_at_diagnosis',\n",
    "        'demographic.vital_status': 'vital_status',\n",
    "        'diagnoses.tumor_grade': 'tumor_grade',\n",
    "        'diagnoses.morphology': 'morphology',\n",
    "        'diagnoses.site_of_resection_or_biopsy': 'site_of_biopsy',\n",
    "        'diagnoses.laterality': 'laterality',\n",
    "        'diagnoses.prior_malignancy': 'prior_malignancy',\n",
    "        'diagnoses.prior_treatment': 'prior_treatment',\n",
    "        'diagnoses.synchronous_malignancy': 'another_malignancy',\n",
    "        'exposures.alcohol_history': 'alcohol_history',\n",
    "        'exposures.alcohol_intensity': 'alcohol_intensity',\n",
    "        'exposures.cigarettes_per_day': 'tobacco_frequency',\n",
    "        'exposures.tobacco_smoking_onset_year': 'tobacco_onset',\n",
    "        'diagnoses.metastasis_at_diagnosis': 'metastasis',\n",
    "        'diagnoses.last_known_disease_status': 'disease_status',\n",
    "        'diagnoses.progression_or_recurrence': 'progression',\n",
    "        'demographic.days_to_death': 'days_to_death',\n",
    "        'follow_ups.karnofsky_performance_status': 'karnofsky_score',\n",
    "        'diagnoses.who_cns_grade': 'who_grade'\n",
    "    }\n",
    "    \n",
    "    # Create a simplified dataframe with mapped columns\n",
    "    df_selected = pd.DataFrame()\n",
    "    for orig_col, new_col in feature_mapping.items():\n",
    "        if orig_col in df.columns:\n",
    "            df_selected[new_col] = df[orig_col]\n",
    "    \n",
    "    # Add target variable\n",
    "    df_selected['severity_level'] = df['severity_level']\n",
    "    \n",
    "    # Remove rows where severity_level is NaN\n",
    "    df_selected = df_selected.dropna(subset=['severity_level'])\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df_selected.drop('severity_level', axis=1)\n",
    "    y = df_selected['severity_level'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Identify columns that actually exist\n",
    "    existing_cols = X.columns.tolist()\n",
    "    \n",
    "    # Separate numerical and categorical\n",
    "    numerical_cols = ['age_at_diagnosis', 'alcohol_intensity', 'tobacco_frequency', \n",
    "                      'tobacco_onset', 'days_to_death', 'karnofsky_score']\n",
    "    numerical_cols = [col for col in numerical_cols if col in existing_cols]\n",
    "    \n",
    "    categorical_cols = [col for col in existing_cols if col not in numerical_cols]\n",
    "    \n",
    "    print(f\"\\nNumerical features: {numerical_cols}\")\n",
    "    print(f\"Categorical features: {categorical_cols}\")\n",
    "    \n",
    "    # Handle missing values and data cleaning\n",
    "    X_processed = X.copy()\n",
    "    \n",
    "    # Process numerical columns\n",
    "    for col in numerical_cols:\n",
    "        # Convert to numeric, coercing errors to NaN\n",
    "        X_processed[col] = pd.to_numeric(X_processed[col], errors='coerce')\n",
    "        \n",
    "        # Get non-NaN values\n",
    "        non_nan_values = X_processed[col].dropna()\n",
    "        \n",
    "        if len(non_nan_values) > 0:\n",
    "            median_val = non_nan_values.median()\n",
    "            X_processed[col] = X_processed[col].fillna(median_val)\n",
    "        else:\n",
    "            # If all values are NaN, fill with 0\n",
    "            X_processed[col] = 0\n",
    "            print(f\"Warning: Column '{col}' has all missing values, filled with 0\")\n",
    "    \n",
    "    # Process categorical columns\n",
    "    for col in categorical_cols:\n",
    "        X_processed[col] = X_processed[col].fillna('Unknown')\n",
    "        X_processed[col] = X_processed[col].astype(str)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_processed[col] = le.fit_transform(X_processed[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Normalize numerical features (only if they exist and have non-zero variance)\n",
    "    if numerical_cols:\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Check for constant columns (zero variance)\n",
    "        for col in numerical_cols:\n",
    "            if X_processed[col].std() == 0:\n",
    "                print(f\"Warning: Column '{col}' has zero variance, skipping normalization\")\n",
    "                continue\n",
    "        \n",
    "        # Only scale columns with variance\n",
    "        cols_to_scale = [col for col in numerical_cols if X_processed[col].std() > 0]\n",
    "        \n",
    "        if cols_to_scale:\n",
    "            X_processed[cols_to_scale] = scaler.fit_transform(X_processed[cols_to_scale])\n",
    "    else:\n",
    "        scaler = None\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    X_final = X_processed.values.astype(np.float32)\n",
    "    \n",
    "    # Check for NaN or Inf values\n",
    "    if np.any(np.isnan(X_final)) or np.any(np.isinf(X_final)):\n",
    "        print(\"Warning: Found NaN or Inf values in processed data. Replacing with 0.\")\n",
    "        X_final = np.nan_to_num(X_final, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Normalize target (0-100 to 0-1)\n",
    "    y_normalized = y / 100.0\n",
    "    \n",
    "    print(f\"\\nFinal processed shape: {X_final.shape}\")\n",
    "    print(f\"Target range: {y_normalized.min():.2f} - {y_normalized.max():.2f}\")\n",
    "    \n",
    "    return X_final, y_normalized, label_encoders, scaler\n",
    "\n",
    "# Feedforward Neural Network Model\n",
    "class MedicalFeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=128, hidden_dim2=64, hidden_dim3=32):\n",
    "        super(MedicalFeedforwardNN, self).__init__()\n",
    "        \n",
    "        # Layer 1: input -> hidden1\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)  # Batch normalization\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Layer 2: hidden1 -> hidden2\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Layer 3: hidden2 -> hidden3\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        # Output layer: hidden3 -> 1 (severity score)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # Output between 0-1 (scaled to 0-100)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.dropout3(out)\n",
    "        \n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid(out)  # Scale to 0-1\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "        for features, labels in train_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"NaN loss detected at epoch {epoch+1}, skipping batch\")\n",
    "                continue\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        avg_loss = epoch_loss / batch_count if batch_count > 0 else float('inf')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            outputs = model(features)\n",
    "            \n",
    "            # Scale back to 0-100\n",
    "            predictions.extend((outputs.cpu().numpy() * 100).flatten())\n",
    "            actuals.extend((labels.cpu().numpy() * 100).flatten())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals)**2))\n",
    "    \n",
    "    print(f'\\nEvaluation Results:')\n",
    "    print(f'Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "    \n",
    "    return predictions, actuals\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV file\n",
    "    # Replace 'your_medical_data.csv' with your actual CSV file path\n",
    "    csv_file_path = 'Downloads/NIH Glioblastoma data.csv'\n",
    "    \n",
    "    try:\n",
    "        # Read CSV file with low_memory=False to handle mixed types\n",
    "        print(f\"Loading data from {csv_file_path}...\")\n",
    "        df = pd.read_csv(csv_file_path, low_memory=False)\n",
    "        \n",
    "        print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
    "        print(f\"\\nSample columns: {list(df.columns[:20])}\")\n",
    "        print(f\"\\nFirst few rows preview:\")\n",
    "        print(df.iloc[:3, :10])\n",
    "        \n",
    "        # The preprocessing function will create severity_level if needed\n",
    "        print(\"\\nPreprocessing data...\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{csv_file_path}' not found. Creating synthetic data for demonstration...\")\n",
    "        # Create synthetic data as fallback\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        sample_data = {\n",
    "            'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "            'race': np.random.choice(['White', 'Black', 'Asian', 'Other'], n_samples),\n",
    "            'ethnicity': np.random.choice(['Hispanic', 'Non-Hispanic'], n_samples),\n",
    "            'age_at_diagnosis': np.random.randint(20, 90, n_samples),\n",
    "            'vital_status': np.random.choice(['Alive', 'Dead', 'Unknown'], n_samples),\n",
    "            'tumor_grade': np.random.choice(['G1', 'G2', 'G3', 'G4'], n_samples),\n",
    "            'morphology': np.random.choice(['8000/3', '8000/6', '8010/3'], n_samples),\n",
    "            'site_of_biopsy': np.random.choice(['Lung', 'Breast', 'Colon', 'Prostate'], n_samples),\n",
    "            'laterality': np.random.choice(['Left', 'Right', 'Bilateral', 'None'], n_samples),\n",
    "            'prior_cancer': np.random.choice(['Yes', 'No'], n_samples),\n",
    "            'prior_treatment': np.random.choice(['Yes', 'No'], n_samples),\n",
    "            'another_malignancy': np.random.choice(['Yes', 'No'], n_samples),\n",
    "            'alcohol_history': np.random.choice(['Yes', 'No', 'Former'], n_samples),\n",
    "            'alcohol_intensity': np.random.randint(0, 10, n_samples),\n",
    "            'tobacco_frequency': np.random.randint(0, 40, n_samples),\n",
    "            'tobacco_onset': np.random.randint(10, 50, n_samples),\n",
    "            'menopause_status': np.random.choice(['Pre', 'Post', 'N/A'], n_samples),\n",
    "            'allergies': np.random.choice(['Yes', 'No'], n_samples),\n",
    "            'pregnancy_outcome': np.random.choice(['Live Birth', 'None', 'Other'], n_samples),\n",
    "            'num_pregnancies': np.random.randint(0, 6, n_samples),\n",
    "            'tumor_descriptors': np.random.choice(['Metastatic', 'Premalignant', 'Localized'], n_samples),\n",
    "            'severity_level': np.random.randint(0, 101, n_samples)  # Target: 0-100\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(sample_data)\n",
    "    \n",
    "    # Preprocess data\n",
    "    X, y, encoders, scaler = preprocess_medical_data(df, create_severity=True)\n",
    "    \n",
    "    print(f\"\\nProcessed data shape: {X.shape}\")\n",
    "    print(f\"Number of features: {X.shape[1]}\")\n",
    "    print(f\"Number of samples: {X.shape[0]}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create datasets and loaders\n",
    "    train_dataset = MedicalDataset(X_train, y_train)\n",
    "    test_dataset = MedicalDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_dim = X.shape[1]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = MedicalFeedforwardNN(input_dim).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training Medical Cancer Severity Prediction Model...\")\n",
    "    train_model(model, train_loader, criterion, optimizer, device, num_epochs=100)\n",
    "    \n",
    "    # Evaluate model\n",
    "    predictions, actuals = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'medical_cancer_severity_model.pth')\n",
    "    print(\"\\nModel saved as 'medical_cancer_severity_model.pth'\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3348a18-ffd9-4fe6-8b2a-7cf99bad0a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
